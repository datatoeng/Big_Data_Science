{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. How do we create RDDs in Spark?\n",
    "\n",
    "RDDs reprensents Resilient Distributed Datasets. They are resilient because they have the ability to always recompute an RDD. They are distributed collections of objects that are computed on different nodes over the cluster.\n",
    "\n",
    "There are mainly three ways to create an RDD in Spark.\n",
    "- Parallelizing already existing collections in driver program, for example converting a list to RDD, which is already created in a driver program.\n",
    "- Referencing a dataset in an external storage system (e.g. HDFS, Hbase, shared file systems or data source offering a Hadoop Input Format).\n",
    "- Creating RDD from already existing RDDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. What are two major categories of transformations on RDDs that Spark provides?\n",
    "\n",
    "There are two types of operations on RDD: “transformation” and “action”. Transformations on RDD are lazy in nature, which means that computations on RDD are not done until we apply an action.\n",
    "\n",
    "- Transformation: refers to the operation applied on a RDD to create new RDD. Filter, groupBy and map are examples of transformations.\n",
    "\n",
    "- Actions: Actions refer to an operation which also applies on RDD, that instructs Spark to perform computation and send the result back to driver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_game = spark.read.option(\"header\",True).csv(\"data/game.csv\")\n",
    "df_game_teams_stats = spark.read.option(\"header\",True).csv(\"data/game_teams_stats.csv\")\n",
    "df_team_info = spark.read.option(\"header\",True).csv(\"data/team_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select two columns - games and seasons - and add a column with total goals (sum of home and away goals). Suggestion: use df.withColumn() function –"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_game_with_total_goals = df_game.select(['game_id', 'season', 'away_goals', 'home_goals'])\n",
    "df_game_with_total_goals = df_game_with_total_goals\\\n",
    ".withColumn('total_goals', df_game_with_total_goals.away_goals+\\\n",
    "            df_game_with_total_goals.home_goals)\\\n",
    ".select('game_id', 'season', 'total_goals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Organize records in ascending order (by season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_game_with_total_goals = df_game_with_total_goals\\\n",
    ".orderBy([\"season\", \"total_goals\"], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Add a column with an average, min and max total score for each season. Suggestion: use Window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType as string\n",
    "from pyspark.sql import Window\n",
    "window = Window.partitionBy(\"season\")\n",
    "\n",
    "df_game_with_total_goals = df_game_with_total_goals\\\n",
    ".withColumn('avg_season_goals', \\\n",
    "            F.bround(F.avg('total_goals').over(window),2))\\\n",
    ".withColumn('min_season_goals', \\\n",
    "            F.min('total_goals').over(window))\\\n",
    ".withColumn('max_season_goals', \\\n",
    "            F.max('total_goals').over(window))\\\n",
    ".orderBy([\"season\", \"total_goals\"], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Add a column that finds a difference between each game’s total score and average for that season. Suggestion: use Window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_game_with_total_goals = df_game_with_total_goals\\\n",
    ".withColumn('diff_goals_to_avg_season_goals', \\\n",
    "            F.bround(df_game_with_total_goals.total_goals - \\\n",
    "                     F.avg('total_goals').over(window),2))\\\n",
    ".orderBy([\"season\", \"total_goals\"], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Print top 10 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----------+----------------+----------------+----------------+------------------------------+\n",
      "|   game_id|  season|total_goals|avg_season_goals|min_season_goals|max_season_goals|diff_goals_to_avg_season_goals|\n",
      "+----------+--------+-----------+----------------+----------------+----------------+------------------------------+\n",
      "|2010020966|20102011|        1.0|            5.59|             1.0|            15.0|                         -4.59|\n",
      "|2010030121|20102011|        1.0|            5.59|             1.0|            15.0|                         -4.59|\n",
      "|2010020761|20102011|        1.0|            5.59|             1.0|            15.0|                         -4.59|\n",
      "|2010030411|20102011|        1.0|            5.59|             1.0|            15.0|                         -4.59|\n",
      "|2010030147|20102011|        1.0|            5.59|             1.0|            15.0|                         -4.59|\n",
      "|2010030124|20102011|        1.0|            5.59|             1.0|            15.0|                         -4.59|\n",
      "|2010020791|20102011|        1.0|            5.59|             1.0|            15.0|                         -4.59|\n",
      "|2010030317|20102011|        1.0|            5.59|             1.0|            15.0|                         -4.59|\n",
      "|2010030231|20102011|        1.0|            5.59|             1.0|            15.0|                         -4.59|\n",
      "|2010030415|20102011|        1.0|            5.59|             1.0|            15.0|                         -4.59|\n",
      "+----------+--------+-----------+----------------+----------------+----------------+------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_game_with_total_goals.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. List all team names (teamName) for teams that played as away team at TD Garden during seasons 2012-2013 and 2013-2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rangers',\n",
       " 'Rangers',\n",
       " 'Rangers',\n",
       " 'Penguins',\n",
       " 'Penguins',\n",
       " 'Maple Leafs',\n",
       " 'Maple Leafs',\n",
       " 'Maple Leafs',\n",
       " 'Maple Leafs',\n",
       " 'Blackhawks',\n",
       " 'Blackhawks',\n",
       " 'Blackhawks',\n",
       " 'Red Wings',\n",
       " 'Red Wings',\n",
       " 'Red Wings',\n",
       " 'Canadiens',\n",
       " 'Canadiens',\n",
       " 'Canadiens',\n",
       " 'Canadiens',\n",
       " 'Hurricanes',\n",
       " 'Red Wings',\n",
       " 'Panthers',\n",
       " 'Panthers',\n",
       " 'Panthers',\n",
       " 'Islanders',\n",
       " 'Senators',\n",
       " 'Lightning',\n",
       " 'Capitals',\n",
       " 'Sabres',\n",
       " 'Senators',\n",
       " 'Flyers',\n",
       " 'Sabres',\n",
       " 'Flames',\n",
       " 'Ducks',\n",
       " 'Panthers',\n",
       " 'Islanders',\n",
       " 'Coyotes',\n",
       " 'Panthers',\n",
       " 'Blue Jackets',\n",
       " 'Sharks',\n",
       " 'Lightning',\n",
       " 'Rangers',\n",
       " 'Blues',\n",
       " 'Hurricanes',\n",
       " 'Canadiens',\n",
       " 'Predators',\n",
       " 'Capitals',\n",
       " 'Senators',\n",
       " 'Hurricanes',\n",
       " 'Penguins',\n",
       " 'Islanders',\n",
       " 'Jets',\n",
       " 'Lightning',\n",
       " 'Wild',\n",
       " 'Kings',\n",
       " 'Red Wings',\n",
       " 'Maple Leafs',\n",
       " 'Jets',\n",
       " 'Capitals',\n",
       " 'Devils',\n",
       " 'Canadiens',\n",
       " 'Blackhawks',\n",
       " 'Avalanche',\n",
       " 'Penguins',\n",
       " 'Rangers',\n",
       " 'Maple Leafs',\n",
       " 'Maple Leafs',\n",
       " 'Senators',\n",
       " 'Flyers',\n",
       " 'Rangers',\n",
       " 'Devils',\n",
       " 'Blue Jackets',\n",
       " 'Canadiens',\n",
       " 'Senators',\n",
       " 'Penguins',\n",
       " 'Sabres',\n",
       " 'Canadiens',\n",
       " 'Canucks',\n",
       " 'Oilers',\n",
       " 'Devils',\n",
       " 'Sabres',\n",
       " 'Maple Leafs',\n",
       " 'Stars',\n",
       " 'Lightning']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_away_teams_season_12_and_13_at_td_garden = df_game.select('season', 'away_team_id', 'venue')\\\n",
    ".join(df_team_info.select('team_id','teamName'), \\\n",
    "      df_game.away_team_id == df_team_info.team_id, \\\n",
    "      how='left')\\\n",
    ".drop('team_id')\\\n",
    ".filter((F.col(\"venue\") == 'TD Garden') &\\\n",
    "        ((F.col(\"season\") == 20122013) |\\\n",
    "         (F.col(\"season\") == 20132014)))\n",
    "df_away_teams_season_12_and_13_at_td_garden\\\n",
    ".select('teamName').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How many unique teams are on the list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_away_teams_season_12_and_13_at_td_garden\\\n",
    ".select('teamName').drop_duplicates().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. \n",
    "\n",
    "Create a data frame that have three columns: Student, Subject, Score. Student name includes: Demar and Kawhi. Subject includes math, history, science. Score can be any number between 0 and 100. The result should be a dataframe with 6 rows and 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_subject_score = sqlContext.createDataFrame(\n",
    "    [('Demar', 'math'),\\\n",
    "     ('Demar', 'history'),\\\n",
    "     ('Demar', 'science'),\\\n",
    "     ('Kawhi', 'math'),\\\n",
    "     ('Kawhi', 'history'),\\\n",
    "     ('Kawhi', 'science')], (\"Student\", \"Subject\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student_subject_score = df_student_subject_score\\\n",
    ".withColumn('Score', F.bround(F.rand()*100, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use user define function to add a category column to the data frame, if score higher than 70, category show ‘Good’, if score higher than 50 but lower than 70, category should show ’Ok’, if score lower than 50 then show ‘Not good’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_score_category(score):\n",
    "    if score > 70:\n",
    "        return \"Good\"\n",
    "    elif score < 50:\n",
    "        return \"Not good\"\n",
    "    else:\n",
    "        return \"Ok\"\n",
    "\n",
    "spark_udf = F.udf(create_score_category, StringType())\n",
    "\n",
    "df_student_subject_score = df_student_subject_score\\\n",
    ".withColumn('Score_Category', spark_udf('Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+--------------+\n",
      "|Student|Subject|Score|Score_Category|\n",
      "+-------+-------+-----+--------------+\n",
      "|  Demar|   math|  6.0|      Not good|\n",
      "|  Demar|history| 26.0|      Not good|\n",
      "|  Demar|science| 58.0|            Ok|\n",
      "|  Kawhi|   math|  1.0|      Not good|\n",
      "|  Kawhi|history| 58.0|            Ok|\n",
      "|  Kawhi|science| 96.0|          Good|\n",
      "+-------+-------+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_student_subject_score.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6.\n",
    "\n",
    "Create a function that when input a number n returns a list of prime numbers between 1 and n.\n",
    "Test your function with number 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_it_prime(number):\n",
    "    # make sure n is a positive integer\n",
    "    number = abs(int(number))\n",
    "    # simple tests\n",
    "    if number < 2:\n",
    "        return False\n",
    "    # 2 is prime\n",
    "    if number == 2:\n",
    "        return True\n",
    "    # other even numbers aren't\n",
    "    if not number & 1:\n",
    "        return False\n",
    "    # check whether number is divisible into it's square root\n",
    "    for x in range(3, int(number**0.5)+1, 2):\n",
    "        if number % x == 0:\n",
    "            return False\n",
    "    #if we get this far we are good\n",
    "    return True\n",
    "\n",
    "from six.moves import xrange\n",
    "def get_prime_numbers_from_1_to_n(n):\n",
    "    # create a set of numbers to 100,000\n",
    "    numbers = sc.parallelize(xrange(n))\n",
    "    print(numbers.filter(is_it_prime).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 7, 11, 13]\n"
     ]
    }
   ],
   "source": [
    "get_prime_numbers_from_1_to_n(17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
